{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":82198,"databundleVersionId":8992710,"sourceType":"competition"}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os,os.path as osp\nfrom glob import glob\nfrom tqdm import tqdm\nimport shutil\nimport random\n\nimport cv2\nimport numpy as np\n\nfrom ultralytics import YOLO\nfrom ultralytics import settings\n\nimport yaml\nfrom sklearn.model_selection import train_test_split\n\nsettings.update({\"wandb\": False})","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-02T11:17:26.462095Z","iopub.execute_input":"2024-07-02T11:17:26.462724Z","iopub.status.idle":"2024-07-02T11:17:30.252181Z","shell.execute_reply.started":"2024-07-02T11:17:26.462689Z","shell.execute_reply":"2024-07-02T11:17:30.251253Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"dataset_dir = '/kaggle/input/vehicle-detection/TrafficPublic'\ntrain_dir = dataset_dir + '/train'\ntest_dir = dataset_dir + '/test'\nsave_dir = '/kaggle/working/yolov8'\nval_ratio = 0.2\n\n# Create folder dataset for yolov8\nos.makedirs(save_dir,exist_ok=True)\nos.makedirs(save_dir + '/' + 'images',exist_ok=True)\nos.makedirs(save_dir + '/' + 'labels',exist_ok=True)\n\nos.makedirs(save_dir + '/' + 'images/train',exist_ok=True)\nos.makedirs(save_dir + '/' + 'labels/train',exist_ok=True)\n\nos.makedirs(save_dir + '/' + 'images/val',exist_ok=True)\nos.makedirs(save_dir + '/' + 'labels/val',exist_ok=True)\n\n# List annotation file  \nann_paths = glob(osp.join(train_dir , '*.txt'))\nann_train, ann_val = train_test_split(ann_paths, test_size=val_ratio)\n\n# Copy train images and labels folder\nprint('Copy images and labels in train folder')\nfor ann_path in tqdm(ann_train):\n    filename = osp.split(ann_path[:-4])[-1]\n    \n    img_path = ann_path[0:-4] + '.jpg'\n    save_img_path = save_dir + '/images/train/' + filename + '.jpg'\n    save_label_path = save_dir + '/labels/train/' + filename + '.txt'\n    \n    if os.path.exists(img_path):  \n        shutil.copy(img_path, save_img_path)\n        shutil.copy(ann_path, save_label_path)\n\n# Copy val images and labels folder\nprint('Copy images and labels in val folder')\nfor ann_path in tqdm(ann_val):\n    filename = osp.split(ann_path[:-4])[-1]\n    \n    img_path = ann_path[0:-4] + '.jpg'\n    save_img_path = save_dir + '/images/val/' + filename + '.jpg'\n    save_label_path = save_dir + '/labels/val/' + filename + '.txt'\n    \n    if os.path.exists(img_path):  \n        shutil.copy(img_path, save_img_path)\n        shutil.copy(ann_path,  save_label_path)\n    \n# Create .yaml yolo format\nprint('Create config file dataset.yaml')\nclasses_list = []\nindex = 0\n\nfor label in open(train_dir + \"/classes.txt\", \"r\").read().split('\\n'): \n    classes_list.append(str(index) + ': ' + label)\n    index += 1\n    \ndata = {\n    \"path\" : save_dir,\n    \"train\" : save_dir + '/' + 'images/train',\n    \"val\" : save_dir + '/' + 'images/val',\n    \"names\" : classes_list\n}\n\nwith open('yolov8/dataset.yaml', 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False, sort_keys=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T11:17:35.765255Z","iopub.execute_input":"2024-07-02T11:17:35.765738Z","iopub.status.idle":"2024-07-02T11:17:53.609839Z","shell.execute_reply.started":"2024-07-02T11:17:35.765708Z","shell.execute_reply":"2024-07-02T11:17:53.608964Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Copy images and labels in train folder\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1459/1459 [00:14<00:00, 102.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Copy images and labels in val folder\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 365/365 [00:03<00:00, 107.54it/s]","output_type":"stream"},{"name":"stdout","text":"Create config file dataset.yaml\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model = YOLO('yolov8x.pt')  # load a pretrained model (recommended for training)\nresults = model.train(data='yolov8/dataset.yaml',project='detect',name = 'train', epochs=20)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T12:14:45.572491Z","iopub.execute_input":"2024-07-02T12:14:45.572864Z","iopub.status.idle":"2024-07-02T12:57:38.130406Z","shell.execute_reply.started":"2024-07-02T12:14:45.572834Z","shell.execute_reply":"2024-07-02T12:57:38.129537Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.2.48 ðŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=yolov8/dataset.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=detect, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=detect/train4\nOverriding model.yaml nc=80 with nc=5\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n 22        [15, 18, 21]  1   8722783  ultralytics.nn.modules.head.Detect           [5, [320, 640, 640]]          \nModel summary: 365 layers, 68157423 parameters, 68157407 gradients, 258.1 GFLOPs\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir detect/train4', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolov8/labels/train.cache... 1458 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1458/1458 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolov8/labels/val.cache... 365 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 365/365 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to detect/train4/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mdetect/train4\u001b[0m\nStarting training for 20 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/20        15G      1.819      1.884      1.595          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:56<00:00,  1.27s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.269      0.384      0.248     0.0973\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/20      15.5G      1.903      1.648       1.67         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:53<00:00,  1.23s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:12<00:00,  1.01s/it]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.267      0.369      0.196     0.0751\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/20        15G      1.886      1.648       1.68         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:52<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.04it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.324      0.349       0.21      0.075\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/20      15.5G      1.847      1.591       1.65          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:52<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.04it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.225      0.369      0.226     0.0947\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/20      15.5G      1.832      1.499      1.608         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:52<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.557      0.442      0.407      0.179\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/20      15.6G      1.776      1.423       1.59         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:52<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.04it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665       0.45      0.432      0.442      0.198\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/20      15.6G      1.752      1.368      1.559         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:52<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.496      0.479      0.468       0.21\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       8/20      15.5G      1.734      1.326      1.563          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:52<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665       0.51      0.495      0.482      0.219\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/20      15.5G      1.712      1.305      1.529         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:52<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.518      0.534      0.515      0.244\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/20      15.5G      1.714      1.272      1.534          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:52<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.564      0.537      0.557      0.265\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Closing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      11/20      15.5G      1.739      1.232      1.578         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:53<00:00,  1.23s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665       0.61      0.537       0.56      0.269\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      12/20      15.5G      1.715      1.195      1.569         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:51<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.571      0.574      0.592      0.289\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      13/20      15.5G      1.696      1.158      1.546          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:51<00:00,  1.21s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.596      0.569      0.589      0.288\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      14/20      15.5G      1.698      1.141       1.56          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:51<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.636      0.554      0.614      0.305\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      15/20      15.5G      1.672      1.088      1.529         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:51<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.568      0.598      0.595      0.299\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      16/20      15.5G      1.635      1.059      1.513          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:51<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.656      0.581      0.628      0.314\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      17/20      15.5G      1.625      1.033      1.489         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:52<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.597      0.618      0.632       0.32\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      18/20      15.5G      1.591      1.009      1.486         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:52<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.673      0.587      0.646      0.326\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      19/20      15.5G       1.57     0.9801      1.456         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:52<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.627      0.626      0.647      0.336\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      20/20      15.5G      1.564      0.959      1.452         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [01:51<00:00,  1.22s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:11<00:00,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.656      0.618      0.664      0.342\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n20 epochs completed in 0.705 hours.\nOptimizer stripped from detect/train4/weights/last.pt, 136.7MB\nOptimizer stripped from detect/train4/weights/best.pt, 136.7MB\n\nValidating detect/train4/weights/best.pt...\nUltralytics YOLOv8.2.48 ðŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 268 layers, 68128383 parameters, 0 gradients, 257.4 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:16<00:00,  1.40s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all        365       2665      0.655      0.618      0.664      0.342\n         0: motorcycle        242        680      0.697      0.504      0.634       0.25\n                1: car        293       1337      0.678      0.732       0.74      0.355\n              2: truck         28         33      0.497      0.455      0.523      0.282\n         3: pickup-van        125        159       0.66       0.61      0.602      0.331\n                4: bus        256        456      0.744      0.789      0.821      0.494\nSpeed: 0.2ms preprocess, 26.2ms inference, 0.0ms loss, 9.5ms postprocess per image\nResults saved to \u001b[1mdetect/train4\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"answer_list = []\n# Use the model\nmodel = YOLO('/kaggle/working/detect/train4/weights/best.pt')\n\nfor file in tqdm(glob(test_dir + '/*')):\n    \n    bbox_list = []\n    cls_list = []\n    scores_list = []\n\n    # Predict on an image\n    results = model(file, verbose=False)\n    # Process results list\n    for result in results:\n        \n        boxes = result.boxes\n        for box in boxes:\n            coor_box = box.xyxy.cpu().numpy().tolist()  # Boxes object for bounding box outputs\n            class_box = box.cls.cpu().numpy().tolist()\n            class_scores = box.conf.cpu().numpy().tolist()\n        \n            bbox_list.append(coor_box[0])\n            cls_list.append(int(class_box[0]))\n            scores_list.append(class_scores[0])\n        \n        value = (file.split('/')[-1], bbox_list, cls_list,scores_list )\n\n    answer_list.append(value)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T12:58:26.597084Z","iopub.execute_input":"2024-07-02T12:58:26.597876Z","iopub.status.idle":"2024-07-02T13:00:17.070523Z","shell.execute_reply.started":"2024-07-02T12:58:26.597843Z","shell.execute_reply":"2024-07-02T13:00:17.069662Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1552/1552 [01:50<00:00, 14.09it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ncolumn_name = ['id','boxes', 'labels', 'scores']\nxml_df = pd.DataFrame(answer_list, columns=column_name)\nxml_df.to_csv('/kaggle/working/submission_yolo8x_20epoch.csv', index=None)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T13:00:23.005131Z","iopub.execute_input":"2024-07-02T13:00:23.005951Z","iopub.status.idle":"2024-07-02T13:00:23.138679Z","shell.execute_reply.started":"2024-07-02T13:00:23.005910Z","shell.execute_reply":"2024-07-02T13:00:23.137775Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}